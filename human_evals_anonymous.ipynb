{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "# Set the display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import matplotlib as plt\n",
    "from PIL import Image\n",
    "from matplotlib.lines import Line2D\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "from scipy.stats import binomtest\n",
    "from collections import defaultdict\n",
    "experiment_version = 1\n",
    "response_version = 1\n",
    "stimuli_path = f\"stimuli_v{experiment_version}/\"\n",
    "response_path = f\"responses_v{experiment_version}/\"\n",
    "dataframe_path = f\"dataframes_v{experiment_version}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE EXPERIMENT DATAFRAME AND TRIAL FILES FOR MEADOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(stimuli_path, exist_ok=True)\n",
    "os.makedirs(response_path, exist_ok=True)\n",
    "os.makedirs(dataframe_path, exist_ok=True)\n",
    "#Experiment column key:\n",
    "# 1: Experiment 1, 2AFC identification for all reconstruction methods\n",
    "# 2: Experiment 2, 2AFC vision vs imagery for all reconstruction methods\n",
    "# 3: Experiment 3, Similarity Score vision vs imagery\n",
    "# 4: Experiment 4, Similarity Score method comparison on conceptual stimuli\n",
    "df_exp = pd.DataFrame(columns=[\"experiment\", \"stim1\", \"stim2\", \"stim3\", \"sample\", \"subject\", \"target_on_left\", \"method\", \"catch_trial\", \"rep\", \"mode\", \"stimtype\"])\n",
    "i=0\n",
    "random_count = 0\n",
    "stimuli_root = \"../output\"\n",
    "for subj in [1,2,5,7]: #1,2,5,7\n",
    "    #Experiment 1, mental imagery two way identification\n",
    "    for mode in [\"vision\", \"imagery\"]:\n",
    "        if mode == \"vision\":\n",
    "            num_samples = 12\n",
    "        else:\n",
    "            num_samples = 18\n",
    "        for sample in tqdm(range(num_samples)):\n",
    "            gt_sample = f\"{sample}_ground_truth\"\n",
    "            if sample < 6:\n",
    "                stimtype = \"simple\"\n",
    "            elif sample < 12:\n",
    "                stimtype = \"complex\"\n",
    "            else:\n",
    "                stimtype = \"concept\"\n",
    "            for method in [\"mirage\", \"iCNN\", \"mindeye\", \"braindiffuser\", \"mindeye2\", \"takagi\"]: \n",
    "                for rep in range(10):\n",
    "                    \n",
    "                    # Get random sample to compare against\n",
    "                    if stimtype == \"simple\":\n",
    "                        random_sample = random.choice([x for x in range(6) if x != sample])\n",
    "                    elif stimtype == \"complex\":\n",
    "                        random_sample = random.choice([x for x in range(6, 12) if x != sample])\n",
    "                    else:\n",
    "                        random_sample = random.choice([x for x in range(12, 18) if x != sample])\n",
    "                    random_rep = random.choice([x for x in range(10)])\n",
    "                    \n",
    "                    sample_recon = f\"{sample}_{rep}_{mode}_subject{subj}_{method}\"\n",
    "                    random_recon = f\"{random_sample}_{random_rep}_{mode}_subject{subj}_{method}\"\n",
    "                    \n",
    "                    # Load the stimulus images and save as pngs to stimuli folder\n",
    "                    gt_sample_path = f\"{stimuli_root}vision/{method}/subject{subj}/{sample}/ground_truth.png\"\n",
    "                    sample_recon_path = f\"{stimuli_root}{mode}/{method}/subject{subj}/{sample}/{rep}.png\"\n",
    "                    random_recon_path = f\"{stimuli_root}{mode}/{method}/subject{subj}/{random_sample}/{random_rep}.png\"\n",
    "                    \n",
    "                    # Copy the stimulus images to the stimuli folder\n",
    "                    shutil.copy(gt_sample_path, f\"stimuli_v{experiment_version}/{gt_sample}.png\")\n",
    "                    shutil.copy(sample_recon_path, f\"stimuli_v{experiment_version}/{sample_recon}.png\")\n",
    "                    shutil.copy(random_recon_path, f\"stimuli_v{experiment_version}/{random_recon}.png\")\n",
    "        \n",
    "                    # Configure stimuli names and order in experiment dataframe\n",
    "                    order = random.randrange(2)\n",
    "                    sample_names = [sample_recon, random_recon]\n",
    "                    left_sample = sample_names.pop(order)\n",
    "                    right_sample = sample_names.pop()\n",
    "                    \n",
    "                    df_exp.loc[i] = {\"experiment\" : 1, \"stim1\" : gt_sample, \"stim2\" : left_sample, \"stim3\" : right_sample, \"sample\" : sample, \"subject\" : subj, \"target_on_left\" : order == 0, \"method\" : method, \"catch_trial\" : None, \"rep\" : rep, \"mode\" : mode, \"stimtype\" : stimtype, \"trial_rep\" : 0}\n",
    "                    i+=1\n",
    "    #Experiment 2, 2AFC vision vs imagery for all reconstruction methods\n",
    "    for sample in tqdm(range(12)):\n",
    "        gt_sample = f\"{sample}_ground_truth\"\n",
    "        for method in [\"mirage\", \"iCNN\", \"mindeye\", \"braindiffuser\", \"mindeye2\", \"takagi\"]: \n",
    "            for rep in range(10):\n",
    "                vision_recon = f\"{sample}_{rep}_vision_subject{subj}_{method}\"\n",
    "                imagery_recon = f\"{sample}_{rep}_imagery_subject{subj}_{method}\"\n",
    "                \n",
    "                # Load the stimulus images and save as pngs to stimuli folder\n",
    "                gt_sample_path = f\"{stimuli_root}vision/{method}/subject{subj}/{sample}/ground_truth.png\"\n",
    "                vision_recon_path = f\"{stimuli_root}vision/{method}/subject{subj}/{sample}/{rep}.png\"\n",
    "                imagery_recon_path = f\"{stimuli_root}imagery/{method}/subject{subj}/{sample}/{rep}.png\"\n",
    "    \n",
    "                # Configure stimuli names and order in experiment dataframe\n",
    "                order = random.randrange(2)\n",
    "                sample_names = [vision_recon, imagery_recon]\n",
    "                left_sample = sample_names.pop(order)\n",
    "                right_sample = sample_names.pop()\n",
    "                if sample < 6:\n",
    "                    stimtype = \"simple\"\n",
    "                elif sample < 12:\n",
    "                    stimtype = \"complex\"\n",
    "                else:\n",
    "                    stimtype = \"concept\"\n",
    "                # \"Target\" is the vision reconstruction\n",
    "                df_exp.loc[i] = {\"experiment\" : 2, \"stim1\" : gt_sample, \"stim2\" : left_sample, \"stim3\" : right_sample, \"sample\" : sample, \"subject\" : subj, \"target_on_left\" : order == 0, \"method\" : method, \"catch_trial\" : None, \"rep\" : rep, \"mode\" : mode, \"stimtype\" : stimtype, \"trial_rep\" : 0}\n",
    "                i+=1\n",
    "    # Experiment 3: Vision vs Imagery similarity comparison w/ the Drag-Rate task\n",
    "    for sample in tqdm(range(12)):\n",
    "        gt_sample = f\"{sample}_ground_truth\"\n",
    "        for method in [\"mirage\", \"iCNN\", \"mindeye\", \"braindiffuser\", \"mindeye2\", \"takagi\"]: \n",
    "            for rep in range(10):\n",
    "                vision_recon = f\"{sample}_{rep}_vision_subject{subj}_{method}\"\n",
    "                imagery_recon = f\"{sample}_{rep}_imagery_subject{subj}_{method}\"\n",
    "                \n",
    "                # Load the stimulus images and save as pngs to stimuli folder\n",
    "                gt_sample_path = f\"{stimuli_root}vision/{method}/subject{subj}/{sample}/ground_truth.png\"\n",
    "                vision_recon_path = f\"{stimuli_root}vision/{method}/subject{subj}/{sample}/{rep}.png\"\n",
    "                imagery_recon_path = f\"{stimuli_root}imagery/{method}/subject{subj}/{sample}/{rep}.png\"\n",
    "    \n",
    "                # Configure stimuli names and order in experiment dataframe\n",
    "                order = random.randrange(2)\n",
    "                sample_names = [vision_recon, imagery_recon]\n",
    "                left_sample = sample_names.pop(order)\n",
    "                right_sample = sample_names.pop()\n",
    "                if sample < 6:\n",
    "                    stimtype = \"simple\"\n",
    "                else:\n",
    "                    stimtype = \"complex\"\n",
    "                df_exp.loc[i] = {\"experiment\" : 3, \"stim1\" : gt_sample, \"stim2\" : left_sample, \"stim3\" : right_sample, \"sample\" : sample, \"subject\" : subj, \n",
    "                                \"target_on_left\" : order == 0, \"method\" : method, \"catch_trial\" : None, \"rep\" : rep, \"mode\" : \"both\", \"stimtype\" : stimtype}\n",
    "                i+=1\n",
    "    # Experiment 4: Method comparison for conceptual stimuli on similarity score task\n",
    "    for sample in tqdm(range(12, 18)):  # samples 12 to 17 (conceptual stimuli)\n",
    "        gt_sample = f\"{sample}_ground_truth\"\n",
    "        stimtype = \"concept\"\n",
    "        for rep in range(10):\n",
    "            # Generate all possible method pairs (15 pairs)\n",
    "            method_pairs = list(itertools.combinations([\"mirage\", \"iCNN\", \"mindeye\", \"braindiffuser\", \"mindeye2\", \"takagi\"], 2))\n",
    "            # Randomly select 9 pairs per sample per subject per repetition\n",
    "            selected_pairs = random.sample(method_pairs, 9)\n",
    "            for method1, method2 in selected_pairs:\n",
    "                # Construct filenames for reconstructions\n",
    "                recon1 = f\"{sample}_{rep}_imagery_subject{subj}_{method1}\"\n",
    "                recon2 = f\"{sample}_{rep}_imagery_subject{subj}_{method2}\"\n",
    "                \n",
    "                # Paths to the images\n",
    "                gt_sample_path = f\"{stimuli_root}imagery/{method1}/subject{subj}/{sample}/ground_truth.png\"\n",
    "                recon1_path = f\"{stimuli_root}imagery/{method1}/subject{subj}/{sample}/{rep}.png\"\n",
    "                recon2_path = f\"{stimuli_root}imagery/{method2}/subject{subj}/{sample}/{rep}.png\"\n",
    "                \n",
    "                # Configure stimuli names, methods are already randomized\n",
    "                sample_names = [recon1, recon2]\n",
    "                left_sample = recon1\n",
    "                right_sample = recon2\n",
    "                \n",
    "                # Record the trial in the dataframe\n",
    "                df_exp.loc[i] = {\"experiment\": 4, \"stim1\": gt_sample, \"stim2\": left_sample, \"stim3\": right_sample, \"sample\": sample, \"subject\": subj, \"target_on_left\": None, \"method\": f\"{method1}_vs_{method2}\", \"catch_trial\": None, \"rep\": rep, \"mode\": \"imagery\", \"stimtype\": stimtype, \"trial_rep\": 0}\n",
    "                i += 1\n",
    "df_exp = df_exp.sample(frac=1)\n",
    "print(len(df_exp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all images are present in final stimuli folder\n",
    "count_not_found = 0\n",
    "stim_path = f\"stimuli_v{experiment_version}/\"\n",
    "for index, row in df_exp.iterrows():\n",
    "    if not (os.path.exists(f\"{stim_path}{row['stim1']}.png\")):\n",
    "        print(f\"{row['stim1']}.png\")\n",
    "        count_not_found += 1\n",
    "    if not (os.path.exists(f\"{stim_path}{row['stim2']}.png\")):\n",
    "        print(f\"{row['stim2']}.png\")\n",
    "        count_not_found += 1\n",
    "    if not (os.path.exists(f\"{stim_path}{row['stim3']}.png\")):\n",
    "        print(f\"{row['stim3']}.png\")\n",
    "        count_not_found += 1\n",
    "print(count_not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add pID columns to assign trials to different participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle Experiments 1, 2, and 3 individually\n",
    "df_exp12 = df_exp[df_exp['experiment'].isin([1,2])].sample(frac=1, random_state=42)\n",
    "df_exp34 = df_exp[df_exp['experiment'].isin([3, 4])].sample(frac=1, random_state=42)\n",
    "\n",
    "# Calculate the number of participants needed\n",
    "exp12_trials_per_participant = 20\n",
    "exp34_trials_per_participant = 10\n",
    "num_participants = max(len(df_exp12) // exp12_trials_per_participant, len(df_exp34) // exp34_trials_per_participant)\n",
    "\n",
    "# Assign pID for Experiment 1\n",
    "df_exp12 = df_exp12.sample(frac=1, random_state=42)  # Re-shuffle to mix experiments 1 and 2\n",
    "df_exp12['pID'] = [i % num_participants for i in range(len(df_exp12))]\n",
    "\n",
    "# Shuffle df_exp34 again before assigning pID to ensure randomness in distribution\n",
    "df_exp34 = df_exp34.sample(frac=1, random_state=42)  # Re-shuffle to mix experiments 3 and 4\n",
    "df_exp34['pID'] = [i % num_participants for i in range(len(df_exp34))]\n",
    "\n",
    "# Combine and shuffle the dataframe to mix up the trials across all experiments\n",
    "df_exp_pid = pd.concat([df_exp12, df_exp34]).sample(frac=1, random_state=42)\n",
    "\n",
    "# Sort by pID to ensure the dataframe is ordered by participant, facilitating even distribution\n",
    "df_exp_pid.sort_values(by='pID', inplace=True)\n",
    "\n",
    "# Ensure pID is the first column\n",
    "cols = list(df_exp_pid.columns)\n",
    "cols.insert(0, cols.pop(cols.index('pID')))\n",
    "df_exp_pid = df_exp_pid[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add catch trials within each pID section\n",
    "df_exp_catch = df_exp_pid.copy()\n",
    "for pID in np.unique(df_exp_catch['pID']):\n",
    "    for experiment_list, num_catch in zip([[1, 2], [3, 4]], [4, 2]): \n",
    "        df_pid = df_exp_catch[(df_exp_catch['experiment'].isin(experiment_list)) & (df_exp_catch['pID'] == pID)]\n",
    "        \n",
    "        # Ground truth catch trials\n",
    "        try:\n",
    "            gt_catch_trials = df_pid.sample(n=num_catch)\n",
    "        except:\n",
    "            print(pID, df_pid)\n",
    "        gt_catch_trials['catch_trial'] = \"ground_truth\"\n",
    "        for index, row in gt_catch_trials.iterrows():\n",
    "            \n",
    "            order = random.randrange(2)\n",
    "            ground_truth = row['stim1']\n",
    "            stims = [ground_truth, row['stim2']]\n",
    "            \n",
    "            gt_catch_trials.at[index, 'stim2'] = stims.pop(order)\n",
    "            gt_catch_trials.at[index, 'stim3'] = stims.pop()\n",
    "            # Target on left here means the ground truth repeat is on the left\n",
    "            gt_catch_trials.at[index, 'target_on_left'] = (order == 0)\n",
    "        df_exp_catch = pd.concat([df_exp_catch, gt_catch_trials])\n",
    "# shuffle catch trials into the sessions\n",
    "df_exp_catch = df_exp_catch.sample(frac=1).sort_values(by='pID', kind='mergesort')\n",
    "print(len(df_exp_catch))\n",
    "print(len(df_exp_catch[(df_exp_catch['pID'] == 0)]))\n",
    "print(len(np.unique(df_exp_catch['pID'])))\n",
    "print(len(df_exp_catch[df_exp_catch['experiment'].isin([1, 2])]))\n",
    "print(len(df_exp_catch[df_exp_catch['experiment'].isin([3, 4])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save experiment dataframe and tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_exp_catch.to_csv(f'dataframes_v{experiment_version}/experiment_v{experiment_version}.csv', index=False)\n",
    "df_catch_exp12 = df_exp_catch[df_exp_catch['experiment'].isin([1, 2])]\n",
    "df_catch_exp34 = df_exp_catch[df_exp_catch['experiment'].isin([3, 4])]\n",
    "\n",
    "df_exp_tsv12 = df_catch_exp12[['pID', 'stim1', 'stim2', 'stim3']].copy()\n",
    "df_exp_tsv34 = df_catch_exp34[['pID', 'stim1', 'stim2', 'stim3']].copy()\n",
    "df_exp_tsv12.to_csv(f\"dataframes_v{experiment_version}/meadow_trials_v{experiment_version}_exp12.tsv\", sep=\"\\t\", index=False, header=False) \n",
    "df_exp_tsv34.to_csv(f\"dataframes_v{experiment_version}/meadow_trials_v{experiment_version}_exp34.tsv\", sep=\"\\t\", index=False, header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE FOLLOWING CELLS ARE FOR PROCESSING RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment = pd.read_csv(dataframe_path + f\"experiment_v{experiment_version}.csv\")\n",
    "\n",
    "df_responses = pd.read_csv(f\"{response_path}annotations_v{response_version}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the responses and associate them with the trials in the experiment dataframe, to have all information available in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a list to hold row dictionaries before creating the final dataframe\n",
    "rows_list = []\n",
    "df_2afc = df_responses[df_responses[\"task\"] == \"Match-To-Sample\"]\n",
    "\n",
    "df_similarity = df_responses[df_responses[\"task\"] == \"Drag-And-Rate\"]\n",
    "# Parse trials in 2AFC experiment\n",
    "for index, row in tqdm(df_2afc.iterrows()):\n",
    "    if row['label'] == row['stim2_id']:\n",
    "        picked_left = True\n",
    "    elif row['label'] == row['stim3_id']:\n",
    "        picked_left = False\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        break\n",
    "    start_timestamp = row['time_trial_start']\n",
    "    end_timestamp = row['time_trial_response']\n",
    "    start = datetime.fromisoformat(start_timestamp.replace(\"Z\", \"+00:00\"))\n",
    "    end = datetime.fromisoformat(end_timestamp.replace(\"Z\", \"+00:00\"))\n",
    "    # Calculate the difference in seconds\n",
    "    response_time = (end - start).total_seconds()\n",
    "    \n",
    "    experiment_row = df_experiment[(df_experiment['experiment'].isin([1,2])) & (df_experiment['stim1'] == row['stim1_name']) & (df_experiment['stim2'] == row['stim2_name']) & (df_experiment['stim3'] == row['stim3_name'])].iloc[0]\n",
    "    row_data = {\n",
    "        **experiment_row.to_dict(),\n",
    "        \"picked_left\": picked_left,\n",
    "        \"picked_target\": picked_left == experiment_row['target_on_left'],\n",
    "        \"participant\": row['participation'],\n",
    "        \"response_time\": response_time,\n",
    "    }\n",
    "    rows_list.append(row_data)\n",
    "# Parse trials in similarity range experiment by iterating through df_responses two rows at a time, since each stimuli has its own row\n",
    "for index in tqdm(range(0, len(df_similarity), 2)):\n",
    "    row1 = df_similarity.iloc[index]\n",
    "    row2 = df_similarity.iloc[index + 1]\n",
    "    # Ensure the two rows belong to the same trial\n",
    "    assert row1[\"trial\"] == row2[\"trial\"], \"Rows do not belong to the same trial\"\n",
    "    \n",
    "    # Attempt to find a matching experiment row\n",
    "    match1 = df_experiment[(df_experiment['experiment'].isin([3,4])) & (df_experiment['stim2'] == row1['stim1_name']) & (df_experiment['stim3'] == row2['stim1_name'])]\n",
    "    match2 = df_experiment[(df_experiment['experiment'].isin([3,4])) & (df_experiment['stim2'] == row2['stim1_name']) & (df_experiment['stim3'] == row1['stim1_name'])]\n",
    "    \n",
    "    # Determine which match is correct\n",
    "    if not match1.empty:\n",
    "        correct_match = match1\n",
    "        stim2_row, stim3_row = row1, row2\n",
    "    elif not match2.empty:\n",
    "        correct_match = match2\n",
    "        stim2_row, stim3_row = row2, row1\n",
    "    else:\n",
    "        continue  # Skip if no correct match is found\n",
    "    \n",
    "    # Extract the correct match's data\n",
    "    experiment_row = correct_match.iloc[0]\n",
    "    \n",
    "    # Calculate response times\n",
    "    start_timestamp = row1['time_trial_start']\n",
    "    end_timestamp1 = row1['time_trial_response']\n",
    "    end_timestamp2 = row2['time_trial_response']\n",
    "    start = datetime.fromisoformat(start_timestamp.replace(\"Z\", \"+00:00\"))\n",
    "    end1 = datetime.fromisoformat(end_timestamp1.replace(\"Z\", \"+00:00\"))\n",
    "    end2 = datetime.fromisoformat(end_timestamp2.replace(\"Z\", \"+00:00\"))\n",
    "    end = max(end1, end2)\n",
    "    response_time = (end - start).total_seconds()\n",
    "    \n",
    "    # Determine if the left stimulus was picked based on the 'y' value\n",
    "    picked_left = stim2_row['y'] > stim3_row['y']\n",
    "    if experiment_row['experiment'] == 4:\n",
    "        methods = experiment_row['method'].split(\"_vs_\")\n",
    "        stim2_method = methods[0]\n",
    "        stim3_method = methods[1]\n",
    "        picked_method = stim2_method if picked_left else stim3_method\n",
    "    else:\n",
    "        stim2_method = experiment_row['method']\n",
    "        stim3_method = experiment_row['method']\n",
    "        picked_method = None\n",
    "    \n",
    "    # Determine target and distractor based on target_on_left flag\n",
    "    if experiment_row['target_on_left']:\n",
    "        target_similarity, target_confidence = stim2_row['y'], stim2_row['x']\n",
    "        distractor_similarity, distractor_confidence = stim3_row['y'], stim3_row['x']\n",
    "    else:\n",
    "        target_similarity, target_confidence = stim3_row['y'], stim3_row['x']\n",
    "        distractor_similarity, distractor_confidence = stim2_row['y'], stim2_row['x']\n",
    "    \n",
    "    # Determine if the target was picked\n",
    "    picked_target = target_similarity > distractor_similarity\n",
    "    \n",
    "    # Compile the row data\n",
    "    row_data = {\n",
    "        **experiment_row.to_dict(),\n",
    "        \"picked_left\": picked_left,\n",
    "        \"participant\": row1['participation'],\n",
    "        \"response_time\": response_time,\n",
    "        \"stim2_similarity\": stim2_row['y'],\n",
    "        \"stim2_confidence\": stim2_row['x'],\n",
    "        \"stim3_similarity\": stim3_row['y'],\n",
    "        \"stim3_confidence\": stim3_row['x'],\n",
    "        \"target_similarity\": target_similarity,\n",
    "        \"target_confidence\": target_confidence,\n",
    "        \"distractor_similarity\": distractor_similarity,\n",
    "        \"distractor_confidence\": distractor_confidence,\n",
    "        \"picked_target\": picked_target,\n",
    "        \"stim2_method\": stim2_method,\n",
    "        \"stim3_method\": stim3_method,\n",
    "        \"picked_method\": picked_method\n",
    "    }\n",
    "    rows_list.append(row_data)\n",
    "\n",
    "# Create the final dataframe from the list of row dictionaries\n",
    "df_trial_combined = pd.DataFrame(rows_list)\n",
    "\n",
    "# Dropping the extra index columns added from the experiment_row.to_dict() conversion\n",
    "df_trial = df_trial_combined.drop(columns=[col for col in df_trial_combined.columns if 'Unnamed' in col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find trials that didn't get completed in the previous round of the experiment, and save new trial files for another round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to count processed trials per pID\n",
    "processed_trials_count = defaultdict(int)\n",
    "\n",
    "# Your existing processing loop goes here...\n",
    "# Update processed_trials_count for each row processed\n",
    "for index, row_data in df_trial.iterrows():\n",
    "    processed_trials_count[row_data['pID']] += 1\n",
    "\n",
    "print(processed_trials_count)\n",
    "\n",
    "# Count expected trials per pID from df_experiment\n",
    "expected_trials_count = df_experiment['pID'].value_counts().to_dict()\n",
    "\n",
    "# Find pIDs with missing trials by comparing processed and expected counts\n",
    "missing_trials_pids = {pID: expected_trials_count[pID] - processed_trials_count[pID] \n",
    "                       for pID in expected_trials_count \n",
    "                       if pID not in processed_trials_count or processed_trials_count[pID] < expected_trials_count[pID]-2}\n",
    "\n",
    "# Print or handle pIDs with missing trials as needed\n",
    "print(f\"missing {len(missing_trials_pids.values())} pIDs\")\n",
    "for pID, missing_count in missing_trials_pids.items():\n",
    "    print(f\"pID: {pID} has {missing_count} missing trials.\")\n",
    "    \n",
    "if len(missing_trials_pids.values()) > 0:\n",
    "    df_exp_missing = df_experiment[df_experiment['pID'].isin(missing_trials_pids.keys())]\n",
    "\n",
    "    df_catch_exp12_missing = df_exp_missing[df_exp_missing['experiment'].isin([1, 2])]\n",
    "    df_catch_exp34_missing = df_exp_missing[df_exp_missing['experiment'].isin([3, 4])]\n",
    "\n",
    "\n",
    "    df_exp_tsv12_missing = df_catch_exp12_missing[['pID', 'stim1', 'stim2', 'stim3']].copy()\n",
    "    df_exp_tsv34_missing = df_catch_exp34_missing[['pID', 'stim1', 'stim2', 'stim3']].copy()\n",
    "    df_exp_tsv12_missing.to_csv(f\"dataframes_v{experiment_version}/meadow_trials_v{experiment_version}_exp12_missing.tsv\", sep=\"\\t\", index=False, header=False) \n",
    "    df_exp_tsv34_missing.to_csv(f\"dataframes_v{experiment_version}/meadow_trials_v{experiment_version}_exp34_missing.tsv\", sep=\"\\t\", index=False, header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse and remove participants that failed at least 2 catch trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of participants\n",
    "print(\"Total participants:\", len(df_trial[\"participant\"].unique()))\n",
    "gt_failures = df_trial[(df_trial['catch_trial'] == 'ground_truth') & (df_trial['picked_target'] == False)].groupby('participant').size()\n",
    "# print(df_trial[(df_trial['catch_trial'] == 'ground_truth')])\n",
    "# Identify participants who failed more than 1 ground truth catch trial\n",
    "participants_to_remove_rule1 = gt_failures[gt_failures > 1].index.tolist()\n",
    "print(\"Participants to remove 1:\", participants_to_remove_rule1)\n",
    "\n",
    "participants_to_remove = set(participants_to_remove_rule1)#.union(set(participants_to_remove_rule2))\n",
    "filtered_df = df_trial[~df_trial['participant'].isin(participants_to_remove)]\n",
    "print(\"Clean participants:\", len(filtered_df[\"participant\"].unique()))\n",
    "print(len(df_trial), len(filtered_df))\n",
    "print(participants_to_remove)\n",
    "# Filter out catch trials\n",
    "filtered_df = filtered_df[(filtered_df['catch_trial'].isnull())]\n",
    "filtered_df.to_csv(f'{dataframe_path}filtered_responses_v{response_version}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE FOLLOWING CELLS ARE FOR ANALYZING RESPONSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filtered responses\n",
    "filtered_df = pd.read_csv(f'{dataframe_path}filtered_responses_v{response_version}.csv')\n",
    "# df_experiment = pd.read_csv(dataframe_path + f\"experiment_v{experiment_version}.csv\")\n",
    "\n",
    "# df_responses = pd.read_csv(f\"{response_path}annotations_v{response_version}.csv\")\n",
    "experiment = 1\n",
    "df_trial_exp = filtered_df[(filtered_df['catch_trial'].isnull()) & (filtered_df['experiment'] == experiment)]\n",
    "\n",
    "# Iterate over each method\n",
    "for method in df_trial_exp['method'].unique():\n",
    "    print(f\"Method: {method}\")\n",
    "    print(\"--------------------\")\n",
    "    for mode in [\"vision\", \"imagery\"]:\n",
    "        \n",
    "        print(f\"Mode: {mode}\")\n",
    "        print(\"--------------------\")\n",
    "        df_trial_exp1 = df_trial_exp[(df_trial_exp['method'] == method) & (df_trial_exp['experiment'] == experiment) & (df_trial_exp['mode'] == mode)]\n",
    "        # Perform a binomial test\n",
    "        # The null hypothesis is that the probability of success is 0.5 (chance level)\n",
    "        if len(df_trial_exp1) == 0:\n",
    "            print(\"No trials for this combination\")\n",
    "            continue\n",
    "        p_value = binomtest(df_trial_exp1['picked_target'].sum(), n=len(df_trial_exp1['picked_target']), p=0.5, alternative='two-sided').pvalue\n",
    "\n",
    "        print(\"Number of experiment trials:\", len(df_trial_exp1))\n",
    "        print(\"Success rate: \", len(df_trial_exp1[df_trial_exp1[\"picked_target\"]]) / len(df_trial_exp1))\n",
    "        print(f'P-value: {p_value}')\n",
    "        \n",
    "        for stimtype in [\"simple\", \"complex\", \"concept\"]:\n",
    "            print(f\"Stimtype: {stimtype}\")\n",
    "            \n",
    "            print(\"--------------------\")\n",
    "            # Filter the data for the current method, mode, and experiment\n",
    "            df_trial_exp1 = df_trial_exp[(df_trial_exp['method'] == method) & (df_trial_exp['experiment'] == experiment) & (df_trial_exp['mode'] == mode) & (df_trial_exp['stimtype'] == stimtype)]\n",
    "            # Perform a binomial test\n",
    "            # The null hypothesis is that the probability of success is 0.5 (chance level)\n",
    "            if len(df_trial_exp1) == 0:\n",
    "                print(\"No trials for this combination\")\n",
    "                continue\n",
    "            p_value = binomtest(df_trial_exp1['picked_target'].sum(), n=len(df_trial_exp1['picked_target']), p=0.5, alternative='two-sided').pvalue\n",
    "\n",
    "            print(\"Number of experiment trials:\", len(df_trial_exp1))\n",
    "            print(\"Success rate: \", len(df_trial_exp1[df_trial_exp1[\"picked_target\"]]) / len(df_trial_exp1))\n",
    "            print(f'P-value: {p_value}')\n",
    "            \n",
    "            print(\"--------------------\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pd.read_csv(f'{dataframe_path}filtered_responses_v{response_version}.csv')\n",
    "experiment = 1\n",
    "df_trial_exp = filtered_df[(filtered_df['catch_trial'].isnull()) & (filtered_df['experiment'] == experiment)]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the percentage of \"picked_target\" values by method and mode\n",
    "percentages = df_trial_exp.groupby(['method', 'mode'])['picked_target'].mean().unstack() * 100\n",
    "\n",
    "# Plot the bar plot\n",
    "ax = percentages.plot(kind='bar', color=['orange', 'blue'], width=0.8)\n",
    "ax.set_ylim(40, 100)  # Set the Y axis to start at 45%\n",
    "ax.axhline(y=50, color='r', linestyle='--')  # Add a dashed horizontal line at 50%\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Percent Correctly Identified')\n",
    "plt.title('Experiment 1:\\nPercent Correctly Identified by Method')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Mode')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Iterate over each unique value of the \"stimtype\" column\n",
    "for stimtype in df_trial_exp['stimtype'].unique():\n",
    "    # Filter the dataframe for the current stimtype\n",
    "    df_stimtype = df_trial_exp[df_trial_exp['stimtype'] == stimtype]\n",
    "    \n",
    "    # Calculate the percentage of \"picked_target\" values by method and mode\n",
    "    percentages = df_stimtype.groupby(['method', 'mode'])['picked_target'].mean().unstack() * 100\n",
    "    \n",
    "    # Plot the bar plot\n",
    "    ax = percentages.plot(kind='bar', color=['orange', 'blue'], width=0.8)\n",
    "    ax.set_ylim(40, 100)  # Set the Y axis to start at 45%\n",
    "    ax.axhline(y=50, color='r', linestyle='--')  # Add a dashed horizontal line at 50%\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Method')\n",
    "    plt.ylabel('Percent Correctly Identified')\n",
    "    plt.title(f'Experiment 1:\\nPercent Correctly Identified by Method for {stimtype.capitalize()} Stimuli')\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(title='Mode')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.ticker as mtick\n",
    "human_df = filtered_df[(filtered_df['experiment'] == 1) & (filtered_df['method'] != \"tagaki\") & (filtered_df['method'] != \"mindeye2\")]# \n",
    "grouped_data = human_df.groupby(['sample', 'subject', 'stimtype', 'mode'])['picked_target'].mean().reset_index()\n",
    "grouped_data.rename(columns={'picked_target': 'Accuracy'}, inplace=True)\n",
    "grouped_data['Accuracy'] *= 100\n",
    "\n",
    "# Function to calculate cumulative distribution\n",
    "def cumulative_distribution(data):\n",
    "    # Sort data\n",
    "    data_sorted = np.sort(data)\n",
    "    # Calculate cumulative probability for each value in the sorted array\n",
    "    p = 100. * np.arange(len(data)) / (len(data) - 1)\n",
    "    return data_sorted, p\n",
    "\n",
    "# Separate the data into the four groups\n",
    "vision_complex = grouped_data[(grouped_data['mode'] == 'vision') & (grouped_data['stimtype'] == 'complex')]['Accuracy']\n",
    "vision_simple = grouped_data[(grouped_data['mode'] == 'vision') & (grouped_data['stimtype'] == 'simple')]['Accuracy']\n",
    "imagery_complex = grouped_data[(grouped_data['mode'] == 'imagery') & (grouped_data['stimtype'] == 'complex')]['Accuracy']\n",
    "imagery_simple = grouped_data[(grouped_data['mode'] == 'imagery') & (grouped_data['stimtype'] == 'simple')]['Accuracy']\n",
    "\n",
    "# Calculate cumulative distributions for each group using the previously defined function\n",
    "vision_complex_sorted, p_vision_complex = cumulative_distribution(vision_complex)\n",
    "vision_simple_sorted, p_vision_simple = cumulative_distribution(vision_simple)\n",
    "imagery_complex_sorted, p_imagery_complex = cumulative_distribution(imagery_complex)\n",
    "imagery_simple_sorted, p_imagery_simple = cumulative_distribution(imagery_simple)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(8, 8), dpi=500)  # Create a square figure\n",
    "ax.plot(vision_simple_sorted, p_vision_simple, color='green', label='Vision Simple', linewidth=3)\n",
    "ax.plot(imagery_simple_sorted, p_imagery_simple, color='orange', label='Imagery Simple', linewidth=3)\n",
    "ax.plot(imagery_complex_sorted, p_imagery_complex, color='red', label='Imagery Complex', linewidth=3)\n",
    "ax.plot(vision_complex_sorted, p_vision_complex, color='blue', label='Vision Complex', linewidth=3)\n",
    "\n",
    "for _ in tqdm(range(1000)):\n",
    "    # Randomize 'picked_target'\n",
    "    randomized_df = human_df.copy()\n",
    "    randomized_df['picked_target'] = np.random.rand(len(randomized_df)) < 0.5\n",
    "\n",
    "    # Group and calculate new accuracies\n",
    "    randomized_grouped_data = randomized_df.groupby(['sample', 'subject', 'method', 'stimtype', 'mode'])['picked_target'].mean().reset_index()\n",
    "    randomized_grouped_data.rename(columns={'picked_target': 'Accuracy'}, inplace=True)\n",
    "    randomized_grouped_data['Accuracy'] *= 100\n",
    "    # Separate the data into the four groups\n",
    "    randomized_vision_complex = randomized_grouped_data[(randomized_grouped_data['mode'] == 'vision') & (randomized_grouped_data['stimtype'] == 'complex')]['Accuracy']\n",
    "    randomized_vision_simple = randomized_grouped_data[(randomized_grouped_data['mode'] == 'vision') & (randomized_grouped_data['stimtype'] == 'simple')]['Accuracy']\n",
    "    randomized_imagery_complex = randomized_grouped_data[(randomized_grouped_data['mode'] == 'imagery') & (randomized_grouped_data['stimtype'] == 'complex')]['Accuracy']\n",
    "    randomized_imagery_simple = randomized_grouped_data[(randomized_grouped_data['mode'] == 'imagery') & (randomized_grouped_data['stimtype'] == 'simple')]['Accuracy']\n",
    "\n",
    "    # Calculate cumulative distributions for each randomized group\n",
    "    r_vision_complex_sorted, r_p_vision_complex = cumulative_distribution(randomized_vision_complex)\n",
    "    r_vision_simple_sorted, r_p_vision_simple = cumulative_distribution(randomized_vision_simple)\n",
    "    r_imagery_complex_sorted, r_p_imagery_complex = cumulative_distribution(randomized_imagery_complex)\n",
    "    r_imagery_simple_sorted, r_p_imagery_simple = cumulative_distribution(randomized_imagery_simple)\n",
    "\n",
    "    # Plot the randomized data\n",
    "    ax.plot(r_vision_simple_sorted, r_p_vision_simple, color=\"gray\", alpha=0.05)\n",
    "    ax.plot(r_vision_complex_sorted, r_p_vision_complex, color=\"gray\", alpha=0.05)\n",
    "    ax.plot(r_imagery_simple_sorted, r_p_imagery_simple, color=\"gray\", alpha=0.05)\n",
    "    ax.plot(r_imagery_complex_sorted, r_p_imagery_complex, color=\"gray\", alpha=0.05)\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel(f'Percentage of Stimuli\\nCorrectly Identified in a 2AFC Task', fontsize=14)\n",
    "ax.set_ylabel('Cumulative Percentage of\\nSamples to Reach Accuracy', fontsize=14)\n",
    "ax.set_title(f'Cumulative Distribution Plot\\nof Human Identification Accuracy (No Takagi or ME2)', fontsize=16)\n",
    "ax.legend(loc='upper left', fontsize=12)\n",
    "ax.grid(True)\n",
    "# plt.tight_layout()\n",
    "# Format x-axis ticks as percentages\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "# Format y-axis ticks as percentages\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "# Set the x-axis limit to end at 100%\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Set the y-axis limit to end at 100%\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "# Ensure the aspect ratio of the plot is equal\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate over each experiment\n",
    "experiment = 1\n",
    "for mode in [\"vision\", \"imagery\"]:\n",
    "    \n",
    "    print(f\"Mode: {mode}\")\n",
    "    for stimtype in [\"simple\", \"complex\", \"concept\"]:\n",
    "        print(f\"Stimtype: {stimtype}\")\n",
    "        # Filter the data for the current method, mode, and experiment\n",
    "        df_trial_exp1 = df_trial_exp[(df_trial_exp['method'] != \"takagi\") & (df_trial_exp['method'] != \"mindeye2\") & (df_trial_exp['experiment'] == experiment) & (df_trial_exp['mode'] == mode) & (df_trial_exp['stimtype'] == stimtype)]\n",
    "        \n",
    "        if len(df_trial_exp1) == 0:\n",
    "                print(\"No trials for this combination\")\n",
    "                continue\n",
    "        # Perform a binomial test\n",
    "        # The null hypothesis is that the probability of success is 0.5 (chance level)\n",
    "        p_value = binomtest(df_trial_exp1['picked_target'].sum(), n=len(df_trial_exp1['picked_target']), p=0.5, alternative='two-sided').pvalue\n",
    "\n",
    "        print(\"Number of experiment trials:\", len(df_trial_exp1))\n",
    "        print(\"Success rate: \", len(df_trial_exp1[df_trial_exp1[\"picked_target\"]]) / len(df_trial_exp1))\n",
    "        print(f'P-value: {p_value}')\n",
    "        \n",
    "        print(\"--------------------\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filtered responses\n",
    "experiment = 2\n",
    "df_trial_exp = filtered_df[(filtered_df['catch_trial'].isnull()) & (filtered_df['experiment'] == experiment)]\n",
    "print(len(df_trial_exp))\n",
    "# # Iterate over each method\n",
    "# for method in df_trial_exp['method'].unique():\n",
    "#         print(f\"Method: {method}\")\n",
    "print(\"--------------------\")\n",
    "for stimtype in [\"simple\", \"complex\", \"concept\"]:\n",
    "        print(f\"Stimtype: {stimtype}\")\n",
    "        # Filter the data for the current method, mode, and experiment\n",
    "        df_trial_exp_stim = df_trial_exp[(df_trial_exp['stimtype'] == stimtype)]\n",
    "        # Perform a binomial test\n",
    "        # The null hypothesis is that the probability of success is 0.5 (chance level)\n",
    "        if len(df_trial_exp_stim) == 0:\n",
    "                print(\"No trials for this combination\")\n",
    "                continue\n",
    "        p_value = binomtest(df_trial_exp_stim['picked_target'].sum(), n=len(df_trial_exp_stim['picked_target']), p=0.5, alternative='two-sided').pvalue\n",
    "\n",
    "        print(\"Number of experiment trials:\", len(df_trial_exp_stim))\n",
    "        print(\"Success rate: \", len(df_trial_exp_stim[df_trial_exp_stim[\"picked_target\"]]) / len(df_trial_exp_stim))\n",
    "        print(f'P-value: {p_value}')\n",
    "\n",
    "        print(\"--------------------\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_trial_exp3 = filtered_df[(filtered_df['catch_trial'].isnull()) & (filtered_df['experiment'] == 3)]\n",
    "# Calculate the average similarity and confidence for each method and stimtype\n",
    "averages = []\n",
    "for method in df_trial_exp3['method'].unique():\n",
    "    # for stimtype in df_trial_exp3['stimtype'].unique():\n",
    "    category_df = df_trial_exp3[(df_trial_exp3[\"method\"] == method)]\n",
    "    avg_vision_similarity = category_df['target_similarity'].mean()\n",
    "    avg_imagery_similarity = category_df['distractor_similarity'].mean()\n",
    "    avg_vision_confidence = category_df['target_confidence'].mean()\n",
    "    avg_imagery_confidence = category_df['distractor_confidence'].mean()\n",
    "    print(f\"Method: {method}, Average Vision Similarity: {avg_vision_similarity:.3f}, Average Vision Confidence: {avg_vision_confidence:.3f}, Average Imagery Similarity: {avg_imagery_similarity:.3f}, Average Imagery Confidence: {avg_imagery_confidence:.3f}\")\n",
    "    averages.append((method, stimtype, avg_vision_similarity, avg_imagery_similarity))\n",
    "\n",
    "# Create a list of methods and their corresponding average similarity values for vision and imagery\n",
    "methods = []\n",
    "vision_similarities = []\n",
    "imagery_similarities = []\n",
    "\n",
    "for method, _, avg_vision_similarity, avg_imagery_similarity in averages:\n",
    "    methods.append(method)\n",
    "    vision_similarities.append(avg_vision_similarity)\n",
    "    imagery_similarities.append(avg_imagery_similarity)\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set the positions of the bars on the X-axis\n",
    "r1 = np.arange(len(methods))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Plot the bars\n",
    "plt.bar(r1, vision_similarities, color='blue', width=bar_width, label='Vision')\n",
    "plt.bar(r2, imagery_similarities, color='orange', width=bar_width, label='Imagery')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Average Similarity')\n",
    "plt.title('Experiment 3:\\nAverage Similarity for Vision and Imagery')\n",
    "plt.xticks([r + bar_width/2 for r in range(len(methods))], methods)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Iterate over each unique value of the \"stimtype\" column\n",
    "for stimtype in df_trial_exp3['stimtype'].unique():\n",
    "    # Filter the dataframe for the current stimtype\n",
    "    df_stimtype = df_trial_exp3[df_trial_exp3['stimtype'] == stimtype]\n",
    "    \n",
    "    # Calculate the average similarity and confidence for each method\n",
    "    averages = []\n",
    "    for method in df_stimtype['method'].unique():\n",
    "        category_df = df_stimtype[df_stimtype[\"method\"] == method]\n",
    "        avg_vision_similarity = category_df['target_similarity'].mean()\n",
    "        avg_imagery_similarity = category_df['distractor_similarity'].mean()\n",
    "        avg_vision_confidence = category_df['target_confidence'].mean()\n",
    "        avg_imagery_confidence = category_df['distractor_confidence'].mean()\n",
    "        averages.append((method, stimtype, avg_vision_similarity, avg_imagery_similarity))\n",
    "    \n",
    "    # Create a list of methods and their corresponding average similarity values for vision and imagery\n",
    "    methods = []\n",
    "    vision_similarities = []\n",
    "    imagery_similarities = []\n",
    "\n",
    "    for method, _, avg_vision_similarity, avg_imagery_similarity in averages:\n",
    "        methods.append(method)\n",
    "        vision_similarities.append(avg_vision_similarity)\n",
    "        imagery_similarities.append(avg_imagery_similarity)\n",
    "\n",
    "    # Set the positions of the bars on the X-axis\n",
    "    r1 = np.arange(len(methods))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "\n",
    "    # Plot the bars\n",
    "    plt.bar(r1, vision_similarities, color='blue', width=bar_width, label='Vision')\n",
    "    plt.bar(r2, imagery_similarities, color='orange', width=bar_width, label='Imagery')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Methods')\n",
    "    plt.ylabel('Average Similarity')\n",
    "    plt.title(f'Experiment 3:\\nAverage Similarity for Vision and Imagery ({stimtype.capitalize()})')\n",
    "    plt.xticks([r + bar_width/2 for r in range(len(methods))], methods)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# human_df = pd.read_csv(f'experiments/dataframes/responses_v4_clean.csv')\n",
    "human_df = filtered_df[(filtered_df['catch_trial'].isnull()) & (filtered_df['experiment'] == 3)]\n",
    "# Grouping and averaging\n",
    "grouped_df = human_df.groupby(['method', 'sample']).mean().reset_index()\n",
    "\n",
    "# Define a clear mapping for method display names in the legend\n",
    "method_display_names = {\n",
    "    \"mirage\" :  \"MIRAGE\",\n",
    "    \"mindeye\": \"MindEye1\",\n",
    "    \"braindiffuser\": \"Brain Diffuser\",\n",
    "    \"iCNN\" : \"iCNN\",\n",
    "    \"mindeye2\": \"MindEye2\",\n",
    "    \"takagi\" : \"Takagi et al.\"\n",
    "}\n",
    "\n",
    "# Prepare the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8), dpi=500)  # Create a square figure\n",
    "bright_palette = sns.color_palette('bright', len(method_display_names))\n",
    "markers = ['o', 's', 'D', '^', 'p', '*']\n",
    "\n",
    "# First, plot the scatter and PCA lines for each method\n",
    "for i, (method_code, method_display) in enumerate(method_display_names.items()):\n",
    "    method_data = grouped_df[grouped_df['method'] == method_code]\n",
    "    # Scatter plot for individual points\n",
    "    sns.scatterplot(data=method_data, x='target_similarity', y='distractor_similarity', color=bright_palette[i], \n",
    "                    label=method_display, s=100, marker=markers[i], alpha=0.7, ax=ax)\n",
    "\n",
    "    # PCA for best fit line\n",
    "    pca = PCA(n_components=2)\n",
    "    points = method_data[['target_similarity', 'distractor_similarity']].dropna()\n",
    "    pca.fit(points)\n",
    "    center = pca.mean_\n",
    "    pc1 = pca.components_[0]\n",
    "    line_x = np.linspace(points['target_similarity'].min() - 0.5, points['target_similarity'].max() + 0.5, 2)\n",
    "    line_y = (pc1[1] / pc1[0]) * (line_x - center[0]) + center[1]\n",
    "    ax.plot(line_x, line_y, color=bright_palette[i], linewidth=2)\n",
    "\n",
    "# Then, plot the large dots for the mean of each method, ensuring they appear on top\n",
    "for i, (method_code, method_display) in enumerate(method_display_names.items()):\n",
    "    method_data = grouped_df[grouped_df['method'] == method_code]\n",
    "    avg_target_similarity = method_data['target_similarity'].mean()\n",
    "    avg_distractor_similarity = method_data['distractor_similarity'].mean()\n",
    "    ax.scatter(avg_target_similarity, avg_distractor_similarity, color=bright_palette[i], marker=markers[i], s=350, edgecolors='black', zorder=5)\n",
    "\n",
    "ax.set_title('Average Human Similarity Scores\\nBetween Vision and Imagery', pad=10, fontsize=16)\n",
    "ax.set_xlabel('Human Similarity Score\\n(Vision Trials)', fontsize=14)\n",
    "ax.set_ylabel('Human Similarity Score\\n(Imagery Trials)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "ax.grid(True)\n",
    "ax.set_xlim(0, 0.7)\n",
    "ax.set_ylim(0, 0.7)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.plot([0, 0.7], [0, 0.7], 'k--')  # Line at unity\n",
    "\n",
    "# Adjusting legend to make sure it represents the latest plotted elements correctly\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Ensuring that new handles created for the legend represent the latest plot elements with the correct zorder\n",
    "new_handles = [plt.Line2D([], [], marker=marker, color='w', markerfacecolor=bright_palette[i], markersize=10, alpha=1) for i, marker in enumerate(markers[:len(method_display_names)])]\n",
    "ax.legend(new_handles, labels[:len(method_display_names)], bbox_to_anchor=(0, 1), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_trial_exp3 = filtered_df[(filtered_df['catch_trial'].isnull()) & (filtered_df['experiment'] == 4)]\n",
    "# Calculate the average similarity and confidence for each method and stimtype\n",
    "averages = []\n",
    "for method in df_trial_exp3['stim2_method'].unique():\n",
    "    # for stimtype in df_trial_exp3['stimtype'].unique():\n",
    "    category_df = df_trial_exp3[(df_trial_exp3[\"stim2_method\"] == method)]\n",
    "    avg_target_similarity = category_df['target_similarity'].mean()\n",
    "    avg_distractor_similarity = category_df['distractor_similarity'].mean()\n",
    "    avg_target_confidence = category_df['target_confidence'].mean()\n",
    "    avg_distractor_confidence = category_df['distractor_confidence'].mean()\n",
    "    print(f\"Method: {method}, Average Method Similarity: {avg_target_similarity:.3f}, Average Method Confidence: {avg_target_confidence:.3f}, Average Distractor Similarity: {avg_distractor_similarity:.3f}, Average Distractor Confidence: {avg_distractor_confidence:.3f}\")\n",
    "    averages.append((method, stimtype, avg_target_similarity, avg_distractor_similarity))\n",
    "\n",
    "# Create a list of methods and their corresponding average similarity values for vision and imagery\n",
    "methods = []\n",
    "target_similarities = []\n",
    "distractor_similarities = []\n",
    "\n",
    "for method, _, avg_target_similarity, avg_distractor_similarity in averages:\n",
    "    methods.append(method)\n",
    "    target_similarities.append(avg_target_similarity)\n",
    "    distractor_similarities.append(avg_distractor_similarity)\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set the positions of the bars on the X-axis\n",
    "r1 = np.arange(len(methods))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Plot the bars\n",
    "plt.bar(r1, target_similarities, color='blue', width=bar_width, label='Target')\n",
    "plt.bar(r2, distractor_similarities, color='orange', width=bar_width, label='Distractor')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Methods')\n",
    "plt.ylabel('Average Similarity')\n",
    "plt.title('Experiment 4: Average Similarity Head to Head: Concepts')\n",
    "plt.xticks([r + bar_width/2 for r in range(len(methods))], methods)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
